'use client';
import { useState, useRef, useCallback } from 'react';

export default function Home() {
  const [isRecording, setIsRecording] = useState(false);
  const [audioUrl, setAudioUrl] = useState('');
  const [recordedTime, setRecordedTime] = useState(0);
  const [volumeLevel, setVolumeLevel] = useState(0);
  const [recordingStatus, setRecordingStatus] = useState('å‡†å¤‡å½•éŸ³');
  const [notes, setNotes] = useState([]);
  const [isGenerating, setIsGenerating] = useState(false);
  const [generatedAudio, setGeneratedAudio] = useState(null);
  const [recognitionConfidence, setRecognitionConfidence] = useState(0);
  const [selectedInstrument, setSelectedInstrument] = useState('handpan');
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [realTimePitches, setRealTimePitches] = useState([]);
  const [detectedKey, setDetectedKey] = useState(''); // æ–°å¢ï¼šæ£€æµ‹åˆ°çš„è°ƒå¼

  const mediaRecorderRef = useRef(null);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const audioChunksRef = useRef([]);
  const recordingIntervalRef = useRef(null);
  const pitchDetectionIntervalRef = useRef(null);
  const detectedPitchesRef = useRef([]);
  const audioDataArrayRef = useRef(null);

  // ä¹å™¨é…ç½®
  const instruments = {
    handpan: {
      name: 'æ‰‹ç¢Ÿ',
      description: 'ç©ºçµå†¥æƒ³çš„æ‰‹ç¢ŸéŸ³è‰²',
      icon: 'ğŸ¥',
      color: '#8B4513'
    },
    piano: {
      name: 'é’¢ç´',
      description: 'å¤å…¸ä¼˜é›…çš„é’¢ç´éŸ³è‰²',
      icon: 'ğŸ¹',
      color: '#2E8B57'
    },
    ambient: {
      name: 'æ°›å›´éŸ³ä¹',
      description: 'ç©ºçµçš„ç¯å¢ƒéŸ³è‰²',
      icon: 'ğŸµ',
      color: '#4682B4'
    }
  };

  // å®Œæ•´çš„éŸ³ç¬¦é¢‘ç‡æ˜ å°„
  const noteFrequencies = {
    'C3': 130.81, 'C#3': 138.59, 'D3': 146.83, 'D#3': 155.56, 'E3': 164.81, 'F3': 174.61,
    'F#3': 185.00, 'G3': 196.00, 'G#3': 207.65, 'A3': 220.00, 'A#3': 233.08, 'B3': 246.94,
    'C4': 261.63, 'C#4': 277.18, 'D4': 293.66, 'D#4': 311.13, 'E4': 329.63, 'F4': 349.23,
    'F#4': 369.99, 'G4': 392.00, 'G#4': 415.30, 'A4': 440.00, 'A#4': 466.16, 'B4': 493.88,
    'C5': 523.25, 'C#5': 554.37, 'D5': 587.33, 'D#5': 622.25, 'E5': 659.25, 'F5': 698.46,
    'F#5': 739.99, 'G5': 783.99, 'G#5': 830.61, 'A5': 880.00, 'A#5': 932.33, 'B5': 987.77,
    'C6': 1046.50
  };

  // æ–°å¢ï¼šè°ƒå¼é…ç½®
  const musicalKeys = {
    'C major': { notes: ['C', 'D', 'E', 'F', 'G', 'A', 'B'], type: 'major' },
    'G major': { notes: ['G', 'A', 'B', 'C', 'D', 'E', 'F#'], type: 'major' },
    'D major': { notes: ['D', 'E', 'F#', 'G', 'A', 'B', 'C#'], type: 'major' },
    'A major': { notes: ['A', 'B', 'C#', 'D', 'E', 'F#', 'G#'], type: 'major' },
    'E major': { notes: ['E', 'F#', 'G#', 'A', 'B', 'C#', 'D#'], type: 'major' },
    'B major': { notes: ['B', 'C#', 'D#', 'E', 'F#', 'G#', 'A#'], type: 'major' },
    'F# major': { notes: ['F#', 'G#', 'A#', 'B', 'C#', 'D#', 'E#'], type: 'major' },
    'C# major': { notes: ['C#', 'D#', 'E#', 'F#', 'G#', 'A#', 'B#'], type: 'major' },
    'F major': { notes: ['F', 'G', 'A', 'A#', 'C', 'D', 'E'], type: 'major' },
    'A minor': { notes: ['A', 'B', 'C', 'D', 'E', 'F', 'G'], type: 'minor' },
    'E minor': { notes: ['E', 'F#', 'G', 'A', 'B', 'C', 'D'], type: 'minor' },
    'B minor': { notes: ['B', 'C#', 'D', 'E', 'F#', 'G', 'A'], type: 'minor' },
    'F# minor': { notes: ['F#', 'G#', 'A', 'B', 'C#', 'D', 'E'], type: 'minor' },
    'C# minor': { notes: ['C#', 'D#', 'E', 'F#', 'G#', 'A', 'B'], type: 'minor' },
    'G# minor': { notes: ['G#', 'A#', 'B', 'C#', 'D#', 'E', 'F#'], type: 'minor' },
    'D# minor': { notes: ['D#', 'E#', 'F#', 'G#', 'A#', 'B', 'C#'], type: 'minor' },
    'A# minor': { notes: ['A#', 'B#', 'C#', 'D#', 'E#', 'F#', 'G#'], type: 'minor' },
    'D minor': { notes: ['D', 'E', 'F', 'G', 'A', 'A#', 'C'], type: 'minor' },
    'G minor': { notes: ['G', 'A', 'A#', 'C', 'D', 'D#', 'F'], type: 'minor' },
    'C minor': { notes: ['C', 'D', 'D#', 'F', 'G', 'G#', 'A#'], type: 'minor' }
  };

  // æ–°å¢ï¼šæ£€æµ‹è°ƒå¼
  const detectMusicalKey = (notes) => {
    if (notes.length === 0) return 'C major';
    
    const noteNames = notes.map(note => {
      const noteName = note.note.replace(/[0-9]/g, ''); // ç§»é™¤æ•°å­—
      return noteName.length > 1 ? noteName[0] + '#' : noteName; // å¤„ç†å‡é™å·
    });
    
    // æ‰¾å‡ºæœ€åŒ¹é…çš„è°ƒå¼
    let bestKey = 'C major';
    let maxMatch = 0;
    
    Object.entries(musicalKeys).forEach(([keyName, key]) => {
      const matchCount = noteNames.filter(note => key.notes.includes(note)).length;
      if (matchCount > maxMatch) {
        maxMatch = matchCount;
        bestKey = keyName;
      }
    });
    
    return bestKey;
  };

  // æ–°å¢ï¼šæ ¹æ®è°ƒå¼ç”Ÿæˆæ‰©å±•éŸ³ç¬¦
  const generateExtendedMelody = (originalNotes, key) => {
    if (originalNotes.length === 0) return originalNotes;
    
    const keyInfo = musicalKeys[key];
    if (!keyInfo) return originalNotes;
    
    const extendedNotes = [...originalNotes];
    
    // è·å–è°ƒå¼å†…çš„æ‰€æœ‰éŸ³ç¬¦ï¼ˆå¤šä¸ªå…«åº¦ï¼‰
    const keyNotes = [];
    for (let octave = 3; octave <= 5; octave++) {
      keyInfo.notes.forEach(note => {
        keyNotes.push(`${note}${octave}`);
      });
    }
    
    // æ·»åŠ è°ƒå¼å†…çš„ç»è¿‡éŸ³å’Œè¾…åŠ©éŸ³
    originalNotes.forEach((note, index) => {
      if (index < originalNotes.length - 1) {
        // åœ¨å½“å‰éŸ³ç¬¦å’Œä¸‹ä¸€ä¸ªéŸ³ç¬¦ä¹‹é—´æ·»åŠ ç»è¿‡éŸ³
        const currentNote = note.note;
        const nextNote = originalNotes[index + 1].note;
        
        // æ‰¾å‡ºè°ƒå¼å†…åˆé€‚çš„ç»è¿‡éŸ³
        const passingNotes = keyNotes.filter(keyNote => {
          const currentFreq = noteFrequencies[currentNote] || 440;
          const nextFreq = noteFrequencies[nextNote] || 440;
          const keyFreq = noteFrequencies[keyNote] || 440;
          
          return keyFreq > Math.min(currentFreq, nextFreq) &&
                 keyFreq < Math.max(currentFreq, nextFreq);
        });
        
        if (passingNotes.length > 0) {
          const selectedPassingNote = passingNotes[Math.floor(Math.random() * passingNotes.length)];
          extendedNotes.splice(extendedNotes.indexOf(note) + 1, 0, {
            note: selectedPassingNote,
            duration: '8n',
            confidence: note.confidence * 0.8,
            type: 'passing'
          });
        }
      }
    });
    
    return extendedNotes.slice(0, 12); // é™åˆ¶æœ€å¤§éŸ³ç¬¦æ•°é‡
  };

  // æ–°å¢ï¼šç”Ÿæˆå’Œå£°è¿›è¡Œ
  const generateHarmonyProgression = (melodyNotes, key) => {
    const keyInfo = musicalKeys[key];
    if (!keyInfo || melodyNotes.length === 0) return [];
    
    const progression = [];
    const scaleDegrees = keyInfo.notes;
    
    // ç®€å•çš„I-IV-V-Iå’Œå£°è¿›è¡Œ
    const chords = [
      [0, 2, 4], // Içº§å’Œå¼¦
      [3, 5, 0], // IVçº§å’Œå¼¦ï¼ˆä¸‹ä¸€ä¸ªå…«åº¦ï¼‰
      [4, 6, 1], // Vçº§å’Œå¼¦
      [0, 2, 4]  // Içº§å’Œå¼¦
    ];
    
    chords.forEach((chord, index) => {
      const chordNotes = chord.map(degree => {
        const noteName = scaleDegrees[degree % scaleDegrees.length];
        const octave = 3 + Math.floor(degree / scaleDegrees.length);
        return `${noteName}${octave}`;
      });
      
      progression.push({
        notes: chordNotes,
        duration: '2n',
        type: 'chord',
        degree: ['I', 'IV', 'V', 'I'][index]
      });
    });
    
    return progression;
  };

  // å¼€å§‹å½•éŸ³ï¼ˆä¿æŒä¸å˜ï¼‰
  const startRecording = useCallback(async () => {
    try {
      setAudioUrl('');
      setRecordedTime(0);
      setVolumeLevel(0);
      setRecordingStatus('è¯·æ±‚éº¦å…‹é£æƒé™...');
      setNotes([]);
      setGeneratedAudio(null);
      setRecognitionConfidence(0);
      setRealTimePitches([]);
      setDetectedKey('');
      audioChunksRef.current = [];
      detectedPitchesRef.current = [];

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100
        }
      });

      setRecordingStatus('åˆå§‹åŒ–éŸ³é¢‘åˆ†æ...');

      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
      analyserRef.current = audioContextRef.current.createAnalyser();
      const source = audioContextRef.current.createMediaStreamSource(stream);
      
      analyserRef.current.fftSize = 2048;
      analyserRef.current.smoothingTimeConstant = 0.8;
      source.connect(analyserRef.current);

      const bufferLength = analyserRef.current.frequencyBinCount;
      audioDataArrayRef.current = new Float32Array(bufferLength);

      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });

      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorderRef.current.onstop = () => {
        if (pitchDetectionIntervalRef.current) {
          clearInterval(pitchDetectionIntervalRef.current);
        }
        
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        const url = URL.createObjectURL(audioBlob);
        setAudioUrl(url);
        setRecordingStatus('åˆ†ææ—‹å¾‹ä¸­...');
        setIsAnalyzing(true);
        
        setTimeout(() => {
          processDetectedPitches();
        }, 1000);
      };

      mediaRecorderRef.current.start(1000);
      setIsRecording(true);
      setRecordingStatus('å½•éŸ³ä¸­...');

      let time = 0;
      recordingIntervalRef.current = setInterval(() => {
        time += 1;
        setRecordedTime(time);
        const volume = 30 + Math.sin(time * 2) * 20 + Math.random() * 10;
        setVolumeLevel(Math.min(100, Math.max(0, volume)));
      }, 1000);

      startRealTimePitchDetection();

    } catch (error) {
      console.error('æ— æ³•è®¿é—®éº¦å…‹é£:', error);
      setRecordingStatus('é”™è¯¯ï¼šæ— æ³•è®¿é—®éº¦å…‹é£');
    }
  }, []);

  // åœæ­¢å½•éŸ³ï¼ˆä¿æŒä¸å˜ï¼‰
  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      
      if (audioContextRef.current) {
        audioContextRef.current.close().catch(console.error);
      }
      
      setIsRecording(false);
      setIsAnalyzing(true);
    }
  }, [isRecording]);

  // å®æ—¶éŸ³é«˜æ£€æµ‹ï¼ˆä¿æŒä¸å˜ï¼‰
  const startRealTimePitchDetection = () => {
    if (!analyserRef.current || !audioDataArrayRef.current) return;
    
    const bufferLength = analyserRef.current.frequencyBinCount;
    const sampleRate = audioContextRef.current.sampleRate;
    
    pitchDetectionIntervalRef.current = setInterval(() => {
      if (!isRecording || !analyserRef.current) return;
      
      analyserRef.current.getFloatFrequencyData(audioDataArrayRef.current);
      const volume = calculateVolume(audioDataArrayRef.current);
      setVolumeLevel(volume);
      
      if (volume > 0.1) {
        const pitchResult = detectPitchFromFrequencyData(audioDataArrayRef.current, sampleRate, bufferLength);
        
        if (pitchResult && pitchResult.confidence > 0.6) {
          const detection = {
            time: Date.now(),
            frequency: pitchResult.frequency,
            note: pitchResult.note,
            confidence: pitchResult.confidence,
            volume: volume
          };
          
          detectedPitchesRef.current.push(detection);
          setRealTimePitches(prev => {
            const newPitches = [...prev, detection];
            return newPitches.slice(-5);
          });
        }
      }
    }, 100);
  };

  // è®¡ç®—éŸ³é‡ï¼ˆä¿æŒä¸å˜ï¼‰
  const calculateVolume = (frequencyData) => {
    let sum = 0;
    for (let i = 0; i < frequencyData.length; i++) {
      if (frequencyData[i] > -100) {
        sum += Math.pow(10, frequencyData[i] / 20);
      }
    }
    const rms = Math.sqrt(sum / frequencyData.length);
    return Math.min(100, rms * 10);
  };

  // ä»é¢‘ç‡æ•°æ®æ£€æµ‹éŸ³é«˜ï¼ˆä¿æŒä¸å˜ï¼‰
  const detectPitchFromFrequencyData = (frequencyData, sampleRate, bufferLength) => {
    if (!frequencyData || frequencyData.length === 0) return null;
    
    let maxMagnitude = -Infinity;
    let maxIndex = 0;
    
    const minIndex = Math.floor(80 * bufferLength / (sampleRate / 2));
    const maxIndexLimit = Math.floor(1000 * bufferLength / (sampleRate / 2));
    
    for (let i = minIndex; i < maxIndexLimit && i < frequencyData.length; i++) {
      if (frequencyData[i] > maxMagnitude && frequencyData[i] > -100) {
        maxMagnitude = frequencyData[i];
        maxIndex = i;
      }
    }
    
    if (maxMagnitude === -Infinity) return null;
    
    const frequency = maxIndex * (sampleRate / 2) / bufferLength;
    return frequencyToNote(frequency);
  };

  // é¢‘ç‡åˆ°éŸ³ç¬¦è½¬æ¢ï¼ˆä¿æŒä¸å˜ï¼‰
  const frequencyToNote = (frequency) => {
    if (frequency < 80 || frequency > 1000) return null;
    
    const noteNames = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
    const A4 = 440;
    
    const noteNumber = Math.round(12 * Math.log2(frequency / A4)) + 57;
    const octave = Math.floor(noteNumber / 12) - 1;
    const noteIndex = noteNumber % 12;
    const noteName = noteNames[noteIndex] + octave;
    
    const expectedFreq = noteFrequencies[noteName];
    if (!expectedFreq) return null;
    
    const cents = 1200 * Math.log2(frequency / expectedFreq);
    const confidence = Math.max(0, 1 - Math.abs(cents) / 50);
    
    return {
      note: noteName,
      frequency: Math.round(frequency * 100) / 100,
      confidence: Math.round(confidence * 100) / 100,
      centsError: Math.round(cents)
    };
  };

  // å¤„ç†æ£€æµ‹åˆ°çš„éŸ³é«˜æ•°æ®ï¼ˆä¿®æ”¹ï¼šåŠ å…¥è°ƒå¼æ£€æµ‹ï¼‰
  const processDetectedPitches = () => {
    const detectedPitches = detectedPitchesRef.current;
    
    if (detectedPitches.length === 0) {
      useIntelligentExample();
      setRecognitionConfidence(0.3);
      setIsAnalyzing(false);
      setRecordingStatus('ä½¿ç”¨ç¤ºä¾‹æ—‹å¾‹');
      setDetectedKey('C major');
      return;
    }
    
    const analyzedMelody = analyzeDetectedPitches(detectedPitches);
    
    // æ£€æµ‹è°ƒå¼
    const detectedKey = detectMusicalKey(analyzedMelody.notes);
    setDetectedKey(detectedKey);
    
    setNotes(analyzedMelody.notes);
    setRecognitionConfidence(analyzedMelody.confidence);
    setIsAnalyzing(false);
    setRecordingStatus(`è¯†åˆ«åˆ° ${analyzedMelody.notes.length} ä¸ªéŸ³ç¬¦ - è°ƒå¼: ${detectedKey}`);
  };

  // åˆ†ææ£€æµ‹åˆ°çš„éŸ³é«˜åºåˆ—ï¼ˆä¿æŒä¸å˜ï¼‰
  const analyzeDetectedPitches = (pitches) => {
    if (pitches.length === 0) {
      return { notes: [], confidence: 0 };
    }
    
    const validPitches = pitches.filter(p => p.confidence > 0.6);
    if (validPitches.length === 0) {
      return { notes: [], confidence: 0 };
    }
    
    const timeWindows = [];
    const windowSize = 300;
    let currentWindow = [];
    let currentWindowStart = validPitches[0].time;
    
    validPitches.forEach(pitch => {
      if (pitch.time - currentWindowStart < windowSize) {
        currentWindow.push(pitch);
      } else {
        if (currentWindow.length > 0) {
          timeWindows.push([...currentWindow]);
        }
        currentWindow = [pitch];
        currentWindowStart = pitch.time;
      }
    });
    
    if (currentWindow.length > 0) {
      timeWindows.push(currentWindow);
    }
    
    const stableNotes = timeWindows.map(window => {
      const noteCount = {};
      window.forEach(pitch => {
        noteCount[pitch.note] = (noteCount[pitch.note] || 0) + pitch.confidence;
      });
      
      const bestNote = Object.keys(noteCount).reduce((a, b) =>
        noteCount[a] > noteCount[b] ? a : b
      );
      
      const notePitches = window.filter(p => p.note === bestNote);
      const avgConfidence = notePitches.reduce((sum, p) => sum + p.confidence, 0) / notePitches.length;
      
      return {
        note: bestNote,
        duration: window.length > 2 ? '4n' : '8n',
        confidence: avgConfidence,
        startTime: window[0].time
      };
    });
    
    const uniqueNotes = [];
    let lastNote = null;
    
    stableNotes.forEach(note => {
      if (!lastNote || note.note !== lastNote.note) {
        uniqueNotes.push({
          note: note.note,
          duration: note.duration,
          confidence: note.confidence
        });
        lastNote = note;
      }
    });
    
    const overallConfidence = uniqueNotes.length > 0
      ? uniqueNotes.reduce((sum, note) => sum + note.confidence, 0) / uniqueNotes.length
      : 0;
    
    return {
      notes: uniqueNotes.slice(0, 8),
      confidence: Math.round(overallConfidence * 100) / 100
    };
  };

  // æ™ºèƒ½ç¤ºä¾‹ï¼ˆä¿æŒä¸å˜ï¼‰
  const useIntelligentExample = () => {
    const intelligentExamples = [
      [
        { note: 'C4', duration: '4n', confidence: 0.8 },
        { note: 'E4', duration: '4n', confidence: 0.8 },
        { note: 'G4', duration: '2n', confidence: 0.8 }
      ],
      [
        { note: 'D4', duration: '4n', confidence: 0.8 },
        { note: 'F4', duration: '4n', confidence: 0.8 },
        { note: 'A4', duration: '2n', confidence: 0.8 }
      ],
      [
        { note: 'G4', duration: '4n', confidence: 0.8 },
        { note: 'B4', duration: '4n', confidence: 0.8 },
        { note: 'D5', duration: '2n', confidence: 0.8 }
      ],
      [
        { note: 'A4', duration: '4n', confidence: 0.8 },
        { note: 'C5', duration: '4n', confidence: 0.8 },
        { note: 'E5', duration: '2n', confidence: 0.8 }
      ]
    ];
    
    const randomExample = intelligentExamples[Math.floor(Math.random() * intelligentExamples.length)];
    setNotes(randomExample);
  };

  // ç”ŸæˆéŸ³ä¹ï¼ˆä¿®æ”¹ï¼šåŠ å…¥è°ƒå¼æ‰©å±•ï¼‰
  const generateSong = async () => {
    if (notes.length === 0) return;
    
    setIsGenerating(true);
    setRecordingStatus('ç”ŸæˆéŸ³ä¹ä¸­...');
    
    try {
      await new Promise(resolve => setTimeout(resolve, 2000));
      
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const sampleRate = 44100;
      const duration = 7;
      const numberOfSamples = sampleRate * duration;
      
      const buffer = audioContext.createBuffer(2, numberOfSamples, sampleRate);
      const leftChannel = buffer.getChannelData(0);
      const rightChannel = buffer.getChannelData(1);
      
      // æ‰©å±•æ—‹å¾‹ï¼šåŠ å…¥è°ƒå¼å†…çš„å…¶ä»–éŸ³ç¬¦
      const extendedMelody = generateExtendedMelody(notes, detectedKey);
      
      // ç”Ÿæˆå’Œå£°è¿›è¡Œ
      const harmonyProgression = generateHarmonyProgression(extendedMelody, detectedKey);
      
      const melodyFreqs = extendedMelody.map(note => noteFrequencies[note.note] || 440);
      
      for (let i = 0; i < numberOfSamples; i++) {
        const time = i / sampleRate;
        
        let leftSample = 0;
        let rightSample = 0;
        
        // ä¸»æ—‹å¾‹
        const noteIndex = Math.floor(time * 2) % melodyFreqs.length;
        const mainFreq = melodyFreqs[noteIndex];
        
        if (mainFreq) {
          // æ ¹æ®ä¹å™¨ç±»å‹ç”ŸæˆéŸ³è‰²
          let instrumentSound = 0;
          switch(selectedInstrument) {
            case 'handpan':
              instrumentSound = Math.sin(2 * Math.PI * mainFreq * time) * 0.4;
              instrumentSound += Math.sin(2 * Math.PI * mainFreq * 2.0 * time) * 0.3;
              instrumentSound += Math.sin(2 * Math.PI * mainFreq * 3.0 * time) * 0.2;
              break;
            case 'piano':
              instrumentSound = Math.sin(2 * Math.PI * mainFreq * time) * 0.3;
              instrumentSound += Math.sin(2 * Math.PI * mainFreq * 2.0 * time) * 0.2;
              break;
            case 'ambient':
              instrumentSound = Math.sin(2 * Math.PI * mainFreq * time * 0.5) * 0.3;
              break;
            default:
              instrumentSound = Math.sin(2 * Math.PI * mainFreq * time) * 0.4;
          }
          
          // å’Œå£°å±‚ - åŸºäºè°ƒå¼çš„å’Œå£°
          const chordIndex = Math.floor(time) % harmonyProgression.length;
          const currentChord = harmonyProgression[chordIndex];
          let harmony = 0;
          
          if (currentChord) {
            currentChord.notes.forEach((chordNote, index) => {
              const chordFreq = noteFrequencies[chordNote] || mainFreq * (index + 1) * 0.5;
              harmony += Math.sin(2 * Math.PI * chordFreq * time) * 0.1;
            });
          }
          
          // ä½éŸ³éƒ¨ - æ ¹éŸ³
          const rootNote = detectedKey.split(' ')[0];
          const rootFreq = noteFrequencies[`${rootNote}3`] || mainFreq * 0.5;
          const bass = Math.sin(2 * Math.PI * rootFreq * time) * 0.2;
          
          const sample = (instrumentSound + harmony + bass) * 0.7;
          const volume = Math.min(1, time / 0.5) * Math.min(1, (duration - time) / 0.5);
          
          leftSample = sample * volume;
          rightSample = sample * volume * 0.9;
        }
        
        leftChannel[i] = leftSample;
        rightChannel[i] = rightSample;
      }
      
      const wavBlob = bufferToWav(buffer);
      const audioUrl = URL.createObjectURL(wavBlob);
      
      setGeneratedAudio({
        url: audioUrl,
        metadata: {
          instrument: instruments[selectedInstrument].name,
          style: getMusicStyle(notes, selectedInstrument),
          duration: '7ç§’',
          title: `${instruments[selectedInstrument].name}æ¼”å¥ - åŸºäºæ‚¨çš„å“¼å”±`,
          generatedAt: new Date().toISOString(),
          source: 'AIæ—‹å¾‹è¯†åˆ«',
          melody: notes.map(n => n.note).join(' '),
          extendedMelody: extendedMelody.map(n => n.note).join(' '),
          key: detectedKey,
          confidence: `è¯†åˆ«ç½®ä¿¡åº¦: ${Math.round(recognitionConfidence * 100)}%`,
          noteCount: `è¯†åˆ«åˆ° ${notes.length} ä¸ªéŸ³ç¬¦`,
          extendedNoteCount: `æ‰©å±•ä¸º ${extendedMelody.length} ä¸ªéŸ³ç¬¦`,
          harmony: `å’Œå£°è¿›è¡Œ: ${harmonyProgression.map(h => h.degree).join(' - ')}`
        },
        blob: wavBlob
      });
      
      setRecordingStatus('éŸ³ä¹ç”Ÿæˆå®Œæˆï¼');
      
    } catch (error) {
      console.error('ç”Ÿæˆé”™è¯¯:', error);
      setRecordingStatus('ç”Ÿæˆå¤±è´¥');
    } finally {
      setIsGenerating(false);
    }
  };

  // å°†AudioBufferè½¬æ¢ä¸ºWAVï¼ˆä¿æŒä¸å˜ï¼‰
  const bufferToWav = (buffer) => {
    const numOfChannels = buffer.numberOfChannels;
    const length = buffer.length * numOfChannels * 2 + 44;
    const bufferArray = new ArrayBuffer(length);
    const view = new DataView(bufferArray);
    const sampleRate = buffer.sampleRate;
    
    const writeString = (offset, string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    let offset = 0;
    writeString(offset, 'RIFF'); offset += 4;
    view.setUint32(offset, length - 8, true); offset += 4;
    writeString(offset, 'WAVE'); offset += 4;
    writeString(offset, 'fmt '); offset += 4;
    view.setUint32(offset, 16, true); offset += 4;
    view.setUint16(offset, 1, true); offset += 2;
    view.setUint16(offset, numOfChannels, true); offset += 2;
    view.setUint32(offset, sampleRate, true); offset += 4;
    view.setUint32(offset, sampleRate * numOfChannels * 2, true); offset += 4;
    view.setUint16(offset, numOfChannels * 2, true); offset += 2;
    view.setUint16(offset, 16, true); offset += 2;
    writeString(offset, 'data'); offset += 4;
    view.setUint32(offset, buffer.length * numOfChannels * 2, true); offset += 4;
    
    for (let channel = 0; channel < numOfChannels; channel++) {
      const channelData = buffer.getChannelData(channel);
      for (let i = 0; i < channelData.length; i++) {
        const sample = Math.max(-1, Math.min(1, channelData[i]));
        view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
        offset += 2;
      }
    }
    
    return new Blob([bufferArray], { type: 'audio/wav' });
  };

  // è·å–éŸ³ä¹é£æ ¼ï¼ˆä¿æŒä¸å˜ï¼‰
  const getMusicStyle = (notes, instrumentType) => {
    const styles = {
      handpan: ['å†¥æƒ³éŸ³ä¹', 'ä¸–ç•ŒéŸ³ä¹', 'æ²»æ„ˆç³»'],
      piano: ['å¤å…¸éŸ³ä¹', 'è½»éŸ³ä¹', 'é’¢ç´ç‹¬å¥'],
      ambient: ['æ°›å›´éŸ³ä¹', 'ç¯å¢ƒéŸ³ä¹', 'å¤ªç©ºéŸ³ä¹']
    };
    
    const instrumentStyles = styles[instrumentType] || styles.handpan;
    return instrumentStyles[notes.length % instrumentStyles.length];
  };

  // é‡æ–°ç”Ÿæˆï¼ˆä¿æŒä¸å˜ï¼‰
  const resetGeneration = () => {
    if (generatedAudio && generatedAudio.url) {
      URL.revokeObjectURL(generatedAudio.url);
    }
    setGeneratedAudio(null);
    setRecordingStatus('å‡†å¤‡å½•éŸ³');
  };

  // æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆä¿æŒä¸å˜ï¼‰
  const formatTime = (seconds) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  // è·å–éŸ³é‡æ¡é¢œè‰²ï¼ˆä¿æŒä¸å˜ï¼‰
  const getVolumeColor = (volume) => {
    if (volume > 70) return '#ff4444';
    if (volume > 40) return '#ffaa00';
    if (volume > 10) return '#00c851';
    return '#cccccc';
  };

  return (
    <div style={{
      padding: '2rem',
      maxWidth: '800px',
      margin: '0 auto',
      fontFamily: 'system-ui',
      backgroundColor: '#f5f5f5',
      minHeight: '100vh'
    }}>
      {/* æ ‡é¢˜åŒºåŸŸ */}
      <div style={{ textAlign: 'center', marginBottom: '2rem' }}>
        <h1 style={{
          fontSize: '2.5rem',
          color: '#333',
          margin: '0 0 0.5rem 0',
          background: 'linear-gradient(135deg, #667eea 0%, #764ba2 100%)',
          WebkitBackgroundClip: 'text',
          WebkitTextFillColor: 'transparent'
        }}>
          ğŸµ AI éŸ³ä¹ç”Ÿæˆå™¨
        </h1>
        <p style={{ fontSize: '1.1rem', color: '#666', margin: 0 }}>
          æ™ºèƒ½æ—‹å¾‹è¯†åˆ« + è°ƒå¼æ‰©å±• + 7ç§’éŸ³ä¹ç”Ÿæˆ
        </p>
      </div>

      {/* ä¹å™¨é€‰æ‹©å™¨ */}
      <div style={{
        backgroundColor: 'white',
        borderRadius: '12px',
        padding: '1.5rem',
        marginBottom: '2rem',
        boxShadow: '0 2px 4px rgba(0, 0, 0, 0.1)'
      }}>
        <h3 style={{ margin: '0 0 1rem 0', color: '#333' }}>ğŸ¼ é€‰æ‹©ä¹å™¨</h3>
        <div style={{ display: 'flex', gap: '1rem', flexWrap: 'wrap' }}>
          {Object.entries(instruments).map(([key, instrument]) => (
            <button
              key={key}
              onClick={() => setSelectedInstrument(key)}
              style={{
                padding: '1rem 1.5rem',
                fontSize: '14px',
                backgroundColor: selectedInstrument === key ? instrument.color : '#f8f9fa',
                color: selectedInstrument === key ? 'white' : '#333',
                border: `2px solid ${selectedInstrument === key ? instrument.color : '#dee2e6'}`,
                borderRadius: '8px',
                cursor: 'pointer',
                transition: 'all 0.3s ease',
                minWidth: '120px'
              }}
            >
              <div style={{ fontSize: '24px', marginBottom: '0.5rem' }}>{instrument.icon}</div>
              <div style={{ fontWeight: 'bold' }}>{instrument.name}</div>
              <div style={{ fontSize: '12px', opacity: 0.8 }}>{instrument.description}</div>
            </button>
          ))}
        </div>
      </div>

      {/* ä¸»æ§åˆ¶é¢æ¿ */}
      <div style={{
        backgroundColor: 'white',
        borderRadius: '12px',
        padding: '2rem',
        boxShadow: '0 4px 6px rgba(0, 0, 0, 0.1)',
        marginBottom: '2rem'
      }}>
        {/* çŠ¶æ€æ˜¾ç¤º */}
        <div style={{
          textAlign: 'center',
          marginBottom: '2rem',
          padding: '1rem',
          backgroundColor: '#f8f9fa',
          borderRadius: '8px',
          border: '1px solid #e9ecef'
        }}>
          <h3 style={{ margin: '0 0 0.5rem 0', color: '#333' }}>
            {recordingStatus}
          </h3>
          <div style={{ fontSize: '2rem', fontWeight: 'bold', color: '#007acc' }}>
            {formatTime(recordedTime)}
          </div>
          {detectedKey && (
            <div style={{ marginTop: '0.5rem', color: '#28a745', fontWeight: 'bold' }}>
              æ£€æµ‹åˆ°è°ƒå¼: {detectedKey}
            </div>
          )}
        </div>

        {/* å½•éŸ³æ§åˆ¶æŒ‰é’® */}
        <div style={{
          display: 'flex',
          gap: '1rem',
          justifyContent: 'center',
          marginBottom: '2rem',
          flexWrap: 'wrap'
        }}>
          {!isRecording ? (
            <button
              onClick={startRecording}
              disabled={isAnalyzing || isGenerating}
              style={{
                padding: '12px 24px',
                fontSize: '16px',
                backgroundColor: isAnalyzing || isGenerating ? '#ccc' : instruments[selectedInstrument].color,
                color: 'white',
                border: 'none',
                borderRadius: '8px',
                cursor: isAnalyzing || isGenerating ? 'not-allowed' : 'pointer',
                fontWeight: 'bold',
                minWidth: '140px'
              }}
            >
              {isAnalyzing ? 'âš¡ åˆ†æä¸­...' : isGenerating ? 'ğŸµ ç”Ÿæˆä¸­...' : 'ğŸ¤ å¼€å§‹å½•éŸ³'}
            </button>
          ) : (
            <button
              onClick={stopRecording}
              style={{
                padding: '12px 24px',
                fontSize: '16px',
                backgroundColor: '#dc3545',
                color: 'white',
                border: 'none',
                borderRadius: '8px',
                cursor: 'pointer',
                fontWeight: 'bold',
                minWidth: '140px'
              }}
            >
              â¹ï¸ åœæ­¢å½•éŸ³
            </button>
          )}
        </div>

        {/* å®æ—¶éŸ³é‡æ˜¾ç¤º */}
        {isRecording && (
          <div style={{ marginBottom: '2rem' }}>
            <div style={{
              display: 'flex',
              alignItems: 'center',
              gap: '1rem',
              marginBottom: '0.5rem'
            }}>
              <span style={{ fontWeight: 'bold', color: '#333', minWidth: '80px' }}>
                å®æ—¶éŸ³é‡:
              </span>
              <div style={{
                flex: 1,
                height: '20px',
                backgroundColor: '#eee',
                borderRadius: '10px',
                overflow: 'hidden'
              }}>
                <div
                  style={{
                    height: '100%',
                    backgroundColor: getVolumeColor(volumeLevel),
                    width: `${volumeLevel}%`,
                    borderRadius: '10px',
                    transition: 'width 0.1s ease'
                  }}
                />
              </div>
              <span style={{ fontWeight: 'bold', color: '#333', minWidth: '40px' }}>
                {Math.round(volumeLevel)}%
              </span>
            </div>
            
            {/* éŸ³é‡å»ºè®® */}
            <div style={{
              fontSize: '12px',
              color: '#666',
              textAlign: 'center',
              marginTop: '0.5rem'
            }}>
              {volumeLevel > 70 ? 'ğŸ”´ éŸ³é‡è¿‡å¤§ - è¯·ç¦»éº¦å…‹é£è¿œä¸€äº›' :
               volumeLevel > 40 ? 'ğŸŸ¢ éŸ³é‡è‰¯å¥½ - ä¿æŒå½“å‰è·ç¦»' :
               volumeLevel > 10 ? 'ğŸŸ¡ éŸ³é‡è¾ƒä½ - è¯·é è¿‘éº¦å…‹é£' :
               'âšª æœªæ£€æµ‹åˆ°å£°éŸ³ - è¯·å¼€å§‹å“¼å”±'}
            </div>
          </div>
        )}

        {/* æ—‹å¾‹è¯†åˆ«ç»“æœ */}
        {notes.length > 0 && (
          <div style={{
            backgroundColor: '#e7f3ff',
            padding: '1.5rem',
            borderRadius: '8px',
            border: '2px dashed #007acc',
            marginBottom: '2rem'
          }}>
            <h4 style={{ margin: '0 0 1rem 0', color: '#007acc' }}>
              ğŸ¼ è¯†åˆ«åˆ°çš„æ—‹å¾‹
            </h4>
            <div style={{
              fontFamily: 'monospace',
              fontSize: '18px',
              fontWeight: 'bold',
              color: '#333',
              marginBottom: '1rem'
            }}>
              {notes.map((note, index) => (
                <span key={index} style={{ marginRight: '15px' }}>
                  {note.note}<span style={{fontSize: '14px', color: '#666'}}>({note.duration})</span>
                </span>
              ))}
            </div>
            
            {/* è°ƒå¼ä¿¡æ¯ */}
            {detectedKey && (
              <div style={{
                padding: '0.5rem',
                backgroundColor: '#d4edda',
                borderRadius: '4px',
                marginBottom: '1rem',
                textAlign: 'center'
              }}>
                <strong>ğŸµ æ£€æµ‹åˆ°è°ƒå¼: {detectedKey}</strong>
                <div style={{ fontSize: '12px', color: '#155724' }}>
                  å°†è‡ªåŠ¨æ·»åŠ è¯¥è°ƒå¼çš„å’Œå£°ä¸ç»è¿‡éŸ³
                </div>
              </div>
            )}
            
            {/* è¯†åˆ«ç½®ä¿¡åº¦æ˜¾ç¤º */}
            {recognitionConfidence > 0 && (
              <div style={{
                padding: '0.5rem',
                backgroundColor: recognitionConfidence > 0.7 ? '#d4edda' :
                               recognitionConfidence > 0.4 ? '#fff3cd' : '#f8d7da',
                borderRadius: '4px',
                textAlign: 'center'
              }}>
                <strong>è¯†åˆ«ç½®ä¿¡åº¦: {Math.round(recognitionConfidence * 100)}%</strong>
                {recognitionConfidence > 0.7 ? ' ğŸ‘ è¯†åˆ«è‰¯å¥½' :
                 recognitionConfidence > 0.4 ? ' ğŸ’¡ è¯†åˆ«ä¸€èˆ¬' : ' âš ï¸ è¯†åˆ«è¾ƒå¼±'}
              </div>
            )}
          </div>
        )}

        {/* ç”ŸæˆéŸ³ä¹æŒ‰é’® */}
        {notes.length > 0 && !generatedAudio && (
          <div style={{ textAlign: 'center' }}>
            <button
              onClick={generateSong}
              disabled={isGenerating}
              style={{
                padding: '15px 30px',
                fontSize: '18px',
                backgroundColor: isGenerating ? '#ccc' : '#007bff',
                color: 'white',
                border: 'none',
                borderRadius: '8px',
                cursor: isGenerating ? 'not-allowed' : 'pointer',
                fontWeight: 'bold'
              }}
            >
              {isGenerating ? 'âš¡ ç”Ÿæˆä¸­...' : `âœ¨ ç”Ÿæˆ${instruments[selectedInstrument].name}éŸ³ä¹`}
            </button>
            {detectedKey && (
              <div style={{ marginTop: '0.5rem', fontSize: '14px', color: '#666' }}>
                å°†åŸºäº {detectedKey} è°ƒå¼ç”Ÿæˆä¸°å¯Œçš„å’Œå£°
              </div>
            )}
          </div>
        )}

        {/* ç”Ÿæˆçš„éŸ³ä¹æ’­æ”¾å™¨ */}
        {generatedAudio && (
          <div style={{
            backgroundColor: '#e8f5e8',
            padding: '1.5rem',
            borderRadius: '8px',
            border: '2px solid #4caf50'
          }}>
            <h4 style={{ margin: '0 0 1rem 0', color: '#2e7d32' }}>
              ğŸµ ç”Ÿæˆçš„éŸ³ä¹
            </h4>
            
            <div style={{ margin: '1rem 0' }}>
              <audio controls style={{ width: '100%' }}>
                <source src={generatedAudio.url} type="audio/wav" />
                æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘æ’­æ”¾ã€‚
              </audio>
            </div>
            
            <div style={{
              display: 'flex',
              gap: '1rem',
              justifyContent: 'center',
              flexWrap: 'wrap',
              marginBottom: '1rem'
            }}>
              <button
                onClick={() => document.querySelector('audio').play()}
                style={{
                  padding: '8px 16px',
                  backgroundColor: '#4caf50',
                  color: 'white',
                  border: 'none',
                  borderRadius: '4px',
                  cursor: 'pointer'
                }}
              >
                â–¶ï¸ æ’­æ”¾
              </button>
              <a
                href={generatedAudio.url}
                download="generated-music.wav"
                style={{
                  padding: '8px 16px',
                  backgroundColor: '#2196f3',
                  color: 'white',
                  textDecoration: 'none',
                  borderRadius: '4px',
                  display: 'inline-block'
                }}
              >
                ğŸ’¾ ä¸‹è½½
              </a>
              <button
                onClick={resetGeneration}
                style={{
                  padding: '8px 16px',
                  backgroundColor: '#ff9800',
                  color: 'white',
                  border: 'none',
                  borderRadius: '4px',
                  cursor: 'pointer'
                }}
              >
                ğŸ”„ é‡æ–°ç”Ÿæˆ
              </button>
            </div>
            
            {/* éŸ³ä¹ä¿¡æ¯ */}
            <div style={{ fontSize: '14px', color: '#666' }}>
              <p><strong>ğŸµ ä¹å™¨:</strong> {generatedAudio.metadata.instrument}</p>
              <p><strong>ğŸ¼ è°ƒå¼:</strong> {generatedAudio.metadata.key}</p>
              <p><strong>âœ¨ å’Œå£°è¿›è¡Œ:</strong> {generatedAudio.metadata.harmony}</p>
              <p><strong>â±ï¸ æ—¶é•¿:</strong> {generatedAudio.metadata.duration}</p>
              <p><strong>ğŸ¯ è¯†åˆ«ç½®ä¿¡åº¦:</strong> {generatedAudio.metadata.confidence}</p>
              <p><strong>ğŸ“Š éŸ³ç¬¦æ‰©å±•:</strong> {generatedAudio.metadata.extendedNoteCount}</p>
            </div>
          </div>
        )}
      </div>

      {/* ä½¿ç”¨è¯´æ˜ */}
      <div style={{
        marginTop: '2rem',
        padding: '1.5rem',
        backgroundColor: 'white',
        borderRadius: '8px',
        boxShadow: '0 2px 4px rgba(0,0,0,0.1)'
      }}>
        <h3>ğŸ’¡ æ–°åŠŸèƒ½ï¼šè°ƒå¼æ‰©å±•</h3>
        <div style={{ lineHeight: '1.6' }}>
          <p><strong>ğŸµ è‡ªåŠ¨è°ƒå¼æ£€æµ‹</strong> - æ ¹æ®æ‚¨çš„å“¼å”±è‡ªåŠ¨è¯†åˆ«æ‰€å±è°ƒå¼ï¼ˆå¤§è°ƒ/å°è°ƒï¼‰</p>
          <p><strong>ğŸ¼ å’Œå£°æ‰©å±•</strong> - è‡ªåŠ¨æ·»åŠ è°ƒå¼å†…çš„I-IV-Vçº§å’Œå¼¦è¿›è¡Œ</p>
          <p><strong>âœ¨ æ—‹å¾‹ä¸°å¯Œ</strong> - åŠ å…¥ç»è¿‡éŸ³ã€è¾…åŠ©éŸ³ç­‰è£…é¥°éŸ³</p>
          <p><strong>ğŸ¹ å¤šä¹å™¨æ”¯æŒ</strong> - ä¸åŒä¹å™¨é‡‡ç”¨ä¸åŒçš„å’Œå£°å¤„ç†æ–¹å¼</p>
          <p><strong>ğŸ“ˆ éŸ³ä¹æ€§æå‡</strong> - ç”Ÿæˆçš„éŸ³ä¹æ›´åŠ ä¸°å¯Œã€å’Œè°ã€ä¸“ä¸š</p>
        </div>
      </div>
    </div>
  );
}


